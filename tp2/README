README file for Programming Assignment 2 (C++ edition)
=====================================================

Your directory should now contain the following files:

 Makefile        -> [course dir]/src/PA2/Makefile
 README
 cool.flex
 test.cl
 lextest.cc      -> [course dir]/src/PA2/lextest.cc
 mycoolc         -> [course dir]/src/PA2/mycoolc
 stringtab.cc    -> [course dir]/src/PA2/stringtab.cc
 utilities.cc    -> [course dir]/src/PA2/utilities.cc
 handle_flags.cc -> [course dir]/src/PA2/handle_flags.cc
 *.d             dependency files
 *.*             other generated files

The include (.h) files for this assignment can be found in 
[course dir]/include/PA2

	The Makefile contains targets for compiling and running your
	program. DO NOT MODIFY.

	The README contains this info. Part of the assignment is to fill
	the README with the write-up for your project. You should
	explain design decisions, explain why your code is correct, and
	why your test cases are adequate. It is part of the assignment
	to clearly and concisely explain things in text as well as to
	comment your code. Just edit this file.

	cool.flex is a skeleton file for the specification of the
	lexical analyzer. You should complete it with your regular
	expressions, patterns and actions. Information on how to do this
	is in the flex manual, which is part of your reader.

	test.cl is a COOL program that you can test the lexical
	analyzer on. It contains some errors, so it won't compile with
	coolc. However, test.cl does not exercise all lexical
	constructs of COOL and part of your assignment is to rewrite
	test.cl with a complete set of tests for your lexical analyzer.

	cool-parse.h contains definitions that are used by almost all parts
	of the compiler. DO NOT MODIFY.

	stringtab.{cc|h} and stringtab_functions.h contains functions
        to manipulate the string tables.  DO NOT MODIFY.

	utilities.{cc|h} contains functions used by the main() part of
	the lextest program. You may want to use the strdup() function
	defined in here. Remember that you should not print anything
	from inside cool.flex! DO NOT MODIFY.

	lextest.cc contains the main function which will call your
	lexer and print out the tokens that it returns.  DO NOT MODIFY.

	mycoolc is a shell script that glues together the phases of the
	compiler using Unix pipes instead of statically linking code.  
	While inefficient, this architecture makes it easy to mix and match
	the components you write with those of the course compiler.
	DO NOT MODIFY.	

        cool-lexer.cc is the scanner generated by flex from cool.flex.
        DO NOT MODIFY IT, as your changes will be overritten the next
        time you run flex.

 	The *.d files are automatically generated Makefiles that capture
 	dependencies between source and header files in this directory.
 	These files are updated automatically by Makefile; see the gmake
 	documentation for a detailed explanation.

Instructions
------------

	To compile your lextest program type:

	% gmake lexer

	Run your lexer by putting your test input in a file 'foo.cl' and
	run the lextest program:

	% ./lexer foo.cl

	To run your lexer on the file test.cl type:

	% gmake dotest

	If you think your lexical analyzer is correct and behaves like
	the one we wrote, you can actually try 'mycoolc' and see whether
	it runs and produces correct code for any examples.
	If your lexical analyzer behaves in an
	unexpected manner, you may get errors anywhere, i.e. during
	parsing, during semantic analysis, during code generation or
	only when you run the produced code on spim. So beware.

	To turnin your work type:

	% gmake submit-clean

	And run the "submit" program following the instructions on the
	course web page.
	
	Running "submit" will collect the files cool.flex, test.cl,
	README, and test.output. Don't forget to edit the README file to
	include your write-up, and to write your own test cases in
	test.cl.

 	You may turn in the assignment as many times as you like.
	However, only the last version will be retained for
	grading.

	If you change architectures you must issue

	% gmake clean

	when you switch from one type of machine to the other.
	If at some point you get weird errors from the linker,	
	you probably forgot this step.

	GOOD LUCK!

---8<------8<------8<------8<---cut here---8<------8<------8<------8<---

--------------------------------------------GRUPO--------------------------------------------------
Ana Laura Fernandes de Oliveira
Fernanda Ribeiro Passos
Juliana Granffild
Pedro Henrique Lima Carvalho
Tarcila Fernanda Resende da Silva

--------------------------------SOBRE O CODIGO DESENVOLVIDO----------------------------------------

O código desenvolvido é um analisador léxico implementado usando a ferramenta Flex para a linguagem de programação COOL. Neste documento, explicaremos a estrutura do codigo e quais tratamentos de erros foram adotados. E importante ressaltar que, para garantirmos a corretude do analisador, sua implementação foi inteiramente baseada no manual da linguagem COOL, de forma a respeitarmos a sua sintaxe. Além disso, testes abrangentes foram aplicados para garantir a veracidade dos outputs produzidos e a eficácia dos tratamentos de erros aplicados.

O analisador léxico é responsável por quebrar o código fonte em "tokens" (como palavras-chave, identificadores, símbolos, literais, etc.) e passá-los para o analisador sintático. Futuramente, o analisador sintático utilizará esses tokens para construir uma árvore de análise sintática que representa a estrutura do programa.

O arquivo começa com uma seção entre %{ e %}. Tudo o que está dentro dessas delimitadoras é copiado literalmente para o arquivo de saída. Nessa seção, estão incluídas as bibliotecas que o analisador usa e algumas definições globais, como o tamanho máximo das constantes de string e os identificadores usados pelo compilador. Também há algumas definições de funções que são usadas posteriormente no código.

A seção seguinte define algumas expressões regulares usadas para reconhecer os diferentes tipos de tokens. Algumas dessas expressões regulares representam operadores de um único caractere, como + e -, enquanto outras representam operadores de vários caracteres, como <= e =>. Além disso, existem expressões regulares para palavras-chave, identificadores, números inteiros e constantes booleanas.

Depois de definir as expressões regulares, o código especifica as regras para reconhecer os diferentes tipos de tokens. Cada regra é composta de uma expressão regular que reconhece o token e um bloco de código que é executado quando a expressão é correspondida. Por exemplo, a seguinte regra reconhece um sinal de adição:

"+" { return '+'; }

A palavra-chave return especifica que o token é um sinal de adição, e o valor de retorno é o caractere +.

Além disso, o código define várias variáveis globais, incluindo um buffer para armazenar constantes de string, uma variável para controlar a profundidade de aninhamento de comentários e variáveis para rastrear informações de depuração, como a linha atual e uma flag verbose.

Tratamento de erros:

O código também trata vários tipos de erros que podem ocorrer durante a análise léxica.

Por exemplo, há uma função stringOversized() que verifica se uma constante de string é maior que o tamanho máximo permitido pela linguagem COOL (1024 caracteres). Se uma constante de string for maior que esse tamanho, um erro é gerado.

Além disso, há uma variável stringSize que é usada para rastrear o tamanho atual de uma constante de string sendo lida. Se uma constante de string contiver mais de 1024 caracteres, a função stringLengthError() é chamada para relatar o erro.

O código também lida com comentários aninhados e erros de sequência de escape de string, definindo estados diferentes para a máquina de estados do analisador léxico.

Finalmente, quando ocorre um erro durante a análise léxica, a função setErrorMessage() é chamada para atribuir uma mensagem de erro à variável cool_yylval.error_msg e interromper o processo de compilação. Isso garante que os erros encontrados sejam passados para o parser.


---------------------------------------------------------------------------------------------------


